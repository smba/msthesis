To assess performance evolution for configurable software systems, it is
required to assess and understand variability of such systems with respect to
various aspects: \emph{First}, to actually assess single variants, knowledge
about the variability model is required to configure the software systems accordingly.
\emph{Second}, obtaining knowledge about feature usage and implementation can
provide meaningful insights. For instance, knowing that most variable code is dependent
on larger numbers of features might be useful information when selecting a
sampling strategy. Similarly, knowing which feature combinations are frequently
involved in conditioning program functionality and behavior can help understand
configuration-related defects. \emph{Last}, since the number of configurations
for most configurable software systems is infeasible, variability assessment faces
performance- and scalability-related problems. That is, assessments are usually
constrained by limited resources.

This chapter describes the first steps in our methodology and
aembraces the following topics: section \ref{sec:untangling} reviews the
synthesis of variability models as well as corresponding analyses of systems' variability;
section \ref{sec:configuration_gen} describes means to generate configurations from variability
models, and section \ref{sec:configuration_sam} discusses different sampling
strategies.

\section{Untangling Variability}\label{sec:untangling}
The idea of designing and developing configurable software systems is driven by
the separation of different concerns, expressed as features of a software
system. A configurable software system is either assembled at compile-time with
respect to its configuration, or tailored to a configuration at
load-time. Both ways of implementing the variability exist in practice. Research
has also proposed a variety of variant-generating implementation techniques for
compile-time variability, ranging from simple preprocessor directives to
features as separate modules \citep{kastner_model_2009}.  A complete survey of means to implement
configurable software systems would likely exceed the scope of this section, yet we intend to discuss in this
section which information regarding variability is required or useful to our
methodology, and how it can be obtained.

\subsection{Family-based Analyses}
As the number of variants for configurable software systems is usually
infeasible, naive analyses of configurable systems are not trivial. Any static
analysis can only assess one variant at a time, as well as dynamic analyses,
which can follow only one execution path. 
In contrast to that, recently,
extended analysis techniques, which are aware of variability of the systems
studied, have emerged \citep{thum_classification_2014}. In particular, these
\emph{family-based} analyses avoid redundant computation, such as visiting a
code section multiple times, and exploit artifacts shared by multiple variants
\citep{thum_classification_2014}. Besides more efficient analysis, family-based
methods incorporate knowledge about valid feature combinations
\citep{thum_classification_2014} and, therefore, connect analysis results with
a context, such as feature combinations, for which the findings hold.
Family-based methods have been widely used across various domains and can
provide useful information when assessing configurable software systems.

\paragraph{Variability-aware Parsing.} \cite{kastner_variability-aware_2011}
have proposed the framework \emph{TypeChef} to enable the construction of
variability-aware parsers. A variability-aware parser, like ordinary parsers,
systematically explores a program to return an abstract representation of the
parsed program. This parse tree, or abstract syntax tree
is the basis for compilers to translate a program, or for further static
analyses including type checking. For a code base with variability expressed by
preprocessor directives, which are evaluated prior to compilation, a
variability-aware parser, however, is able to derive a parse tree considering
all variants in a single run. A parse tree usually consists of nodes
representing syntactical features of the parsed program. The parse tree
returned by a variability-aware parser, moreover, comprehends variable segments
of a program and will include them with respect to their presence conditions.
For instance, a class may contain a function sort, for which two different
implementations exist. While there might be numerous variants, the parse tree
of the class will contain a node with two children, one for each
implementation; higher numbers of alternative implementations are expresses by
nesting further nodes. In that way, variable and invariant program segments
can be separated.

While the approach of \cite{kastner_variability-aware_2011} handles
undisciplined usage of preprocessor directives, such as splitting function parameter lists, variable types, or
expressions, \cite{medeiros_discipline_2017} have proposed an approach to avoid and
conservatively refactor those cases. The authors propose a catalog of
refactoring templates, which describe transformations from undisciplined usage
of preprocessor annotations to disciplined ones. With respect to
variability-aware parsing, disciplined usage is conceived as using preprocessor
annotations only to segment statements, but not to segment a single syntactical
unit, such as expressions \citep{medeiros_discipline_2017}.

\paragraph{Staged Variability.} Besides variability-aware parsing,
\cite{nguyen_building_2014} have applied symbolic execution
\citep{king_symbolic_1976,darringer_applications_1978} to unwind variability for
PHP Web applications. Web applications are staged, i.e., even though they can be
configured at load-time, the application is as well variable with respect to
input received at run-time. For instance, consider WordPress, a popular content
management system (CMS) implemented in PHP, which can be extended with a number
of plug-ins. However, the content of a website presented to the user also depends
on information retrieved from a database, and user input. Consequently, a
dynamic PHP Web application is staged in a sense that it generates configurable
HTML templates which are rendered at run-time. The authors utilize a symbolic
execution to explore all possible execution paths. Each user input or database
query is considered a symbolic value which is propagated through each script.
By keeping track of the (partially symbolic) HTML output and organizing it in a
DOM-like structure, their approach approximates the HTML output, which
subsequently can be tested, for instance for validity
\citep{nguyen_auto-locating_2011}.

Similarly, \cite{lillack_tracking_2014} have applied taint-analysis to configurable software
systems to track the influence of configuration options read at load-time.
Their static analysis approach taints every value resulting from reading a
configuration parameter as well as every value resulting from a computation
that involves previously tainted values. That way, lines of code that are
possibly depending on configuration options are detected.

\paragraph{Build System Variability.} Apart from
configuring software systems using preprocessor annotations, the assembling of
a configurable software system can as well be orchestrated by its underlying
build system. While preprocessor annotations virtually separate code fragments
of different features, for instance, build systems can physically exclude files
from compilation. This variability enabled by build systems, in particular of
Makefiles has been subject to a couple of analysis approaches. \cite{tamrawi_build_2012} have
proposed Symake, a symbolic execution engine to evaluate Makefiles.
On top of Symake, \cite{zhou_extracting_2015} use symbolic execution to analyze
Makefiles and derive file presence conditions, stating under which feature
selection a file is included or excluded from compilation. The work of
\cite{al-kofahi_escaping_2016} addresses a more advanced build system, GNU Automake.
Automake describes a staged build process, where a Makefile can be specified on
a higher level, and is subsequently compiled to an actual Makefile. The
authorsâ€™ aim to provide a variability-aware representation of all possible
Makefiles to enable further analyses of the build process.

\subsection{Variability Model Synthesis} \label{sec:feature_model_synthesis} 
A variability model as an abstraction of functionality of a software system is
required, or at least of great interest, in many contexts. Not every
configurable system provides an explicit representation of its variability
model. The reasons for inexplicit or absent configuration specification are
manifold. They can range from poor or inconsistent documentation \cite{rabkin_static_2011} to
overly complex configurability \citep{xu_hey_2015}, or configuration constraints
originated in different layers of a software system, such as build constraints or compiler constraints \cite{nadi_where_2015}. The
following paragraphs review different strategies to extract of features and
feature models from different types of artifacts.

\begin{figure}[h!]
\centering
\begin{tikzpicture}[sibling distance=13em,
  every node/.style = {rounded corners,
    draw, align=center,
    top color=white, bottom color=blue!20},thick,scale=0.95, every
    node/.style={scale=0.95}]
  \node {Variability Model Synthesis}
    child { node [align=left] {{\begin{tabular}{c}NLP-based Extraction \\
    \citep{alves_exploratory_2008} \\ \citep{bakar_feature_2015}
    \end{tabular}}}} 
    child { node [align=left] {\begin{tabular}{c} Static Analyses\end{tabular}}
    	child { node [align=left] {\begin{tabular}{c} Feature Extraction \\
    	\citep{rabkin_static_2011}
    	\end{tabular}}} 
    	child { node [align=left] {\begin{tabular}{c} Constraint Extraction \\
    	\citep{nadi_mining_2014,nadi_where_2015}
    	\end{tabular}}} }
    child { node [align=left] {\begin{tabular}{c} Feature-Model
    Approximation \\
    \citep{lopez-herrejon_reverse_2012,lopez-herrejon_assessment_2015} \\
    \citep{linsbauer_feature_2014}\end{tabular}}};
\end{tikzpicture}
\caption{Overview of our literature survey on
variability model synthesis.}\label{fig:varsynth_overview}
\end{figure}
\paragraph{NLP-based Extraction.} As feature diagrams group and organize
features (representing functionality), synthesizing a variability model has shown to be applicable to extract features
and constraints from natural language artifacts. For instance, by comparing
product specifications for an existing market domain, variability models can
provide a detailed feature summary \citep{alves_exploratory_2008}.

The basic idea is to identify commonalities and differences in natural language
documents, such as product descriptions, requirements, or documentations, by
using natural language processing (NLP) techniques \citep{bakar_feature_2015}. A
widely employed technique is to conceive a text as a vector in a vector space model, where each word or
token represents a dimension. From the tokenized text, irrelevant stop words
are removed, and all remaining words are reduced to their original word stems.
The importance of all remaining tokens is (usually) weighed by its tf-idf
value, an established technique in information retrieval. That is, each text
(corresponding to a variant or configuration) is represented as a vector of
tf-idf values in the aforementioned vector space model. 

Based on these representations, text instances are clustered to identify
commonalities and differences, for instance in terms of shared words.
Subsequently, the clustering information can be used to extract features or entire feature
models \citep{alves_exploratory_2008,bakar_feature_2015}.

%\subsection{Feature Extraction} 
%The first objective in recovering a variability model from a configurable
%system is to determine the available configuration options to select
%from. In addition, for further configuration, the type of each configuration
%option (e.g., boolean, numeric, or string) and the respective domain of valid
%values needs to be specified.

\paragraph{Feature Extraction.} \cite{rabkin_static_2011} proposed a static, yet
heuristic approach to extract configuration options along with respective types and domains. Their approach
exploits the usage of configuration APIs and works
in two stages. It commences with extracting all code sections where
configuration options are parsed. Next, configuration names can be
recovered as they are either already specified at compile-time or can be
reconstructed using string analysis yielding respective regular expressions.
Moreover, the authors employ a number of heuristics to infer the type of parsed
options as well as respective domains. First, the return type of the
parsing method is likely to indicate the type of the configuration option read.
Second, if a string is read initially, the library method it is passed to can
reveal valuable information about the actual type. For instance, a method
\emph{parseInteger} is likely to parse an integer value. Third, whenever a
parsed configuration option is compared against a constant, expression, or value
of an enum class, these might indicate valid values or at least corner cases of
the configuration option domain. The extraction method by
\cite{rabkin_static_2011} is precise, but limited, for instance, when an
option leaves the scope of the source code.
Nonetheless, for the systems studied, the authors were able to recover
configuration options that were not documented, only used for debugging or even not used at
all.

\paragraph{Constraint Extraction.} 
A more comprehensive investigation of configuration
constraints and their origin is provided by \cite{nadi_mining_2014,nadi_where_2015}. They use variability-aware parsing to infer constraints by
evaluating makefiles and  analyzing preprocessor directives. Inferred
constraints result from violations of two assumed rules, where (a) every valid
configuration must not contain build-time errors and (b) every valid
configuration should result in a lexically different program. While the
first rule aims at inferring constraints that prevent build-time errors, the
second one is intended to detect features without any effect, at least as part
of some configurations. Their analysis has shown a high accuracy
in recovering constraints with 93\,\% for constraints inferred by the first rule
and 77\,\% for second one respectively. However, their approach
recovered only 28\,\% of all constraints present in the software system.
Further qualitative investigation, including developer interviews, lead to
the conclusion that most of existing constraints stem from domain knowledge
\citep{nadi_where_2015}.

\paragraph{Feature-Model Approximation.}
A different strategy to recover variability models, instead of analyzing the
software artifacts, is to approximate a model. Given a selection of valid
feature selections, a variability model best describing the configurations can
be approximated, or learned. \cite{lopez-herrejon_assessment_2015} have surveyed
different search-based strategies to synthesize feature models of which we
present two categories. Evolutionary algorithms have been applied to reverse
engineer feature models from configuration samples
\citep{lopez-herrejon_reverse_2012,linsbauer_feature_2014}. A population of
feature models is generated and each instance is evaluated by a fitness function, measuring how well it fits the given sample configurations. Subsequently, a new generation is obtained by applying
crossover and mutation operators to the previous generation, whereby only the
fittest remain. This process of evolution is repeated multiple times until a
desired threshold fitness is reached for a feature model instance.
\cite{lopez-herrejon_reverse_2012} identify a trade-off between the accuracy of
recovered feature models and the number of generations employed by evolutionary
algorithms. Besides promising results, the authors stress the importance of
effective and scalable fitness functions as well as meaningful samples to learn
the feature model from.
Contrary to evolutionary algorithms,
\cite{haslinger_reverse_2011,haslinger_extracting_2013} have proposed an ad-hoc
algorithm to reverse engineer feature models. The algorithm recovers
the feature model layer by layer via extracting all child
features for a given parent feature recursively. The algorithm does not consider
cross-tree constraints.
Besides promising results for basic feature models, the authors advocate the
incorporation of human domain-knowledge in the synthesis of feature models.
 
\paragraph{Feature-Hierarchy Recovery} \label{sec:feature_hierarchy}
Besides recovering features and their respective constraints, to reverse
engineer a feature model, one further step is required when the outcome should
be human readable in a feature diagram. The recovered knowledge can be
organized in a tree-like hierarchy with feature groups specified and cross-tree
constraints explicitly stated to derive a valid feature diagram
\citep{kang_feature-oriented_1990}.
While several approaches for recovering the feature-model hierarchy have been
proposed, we are primarily interested in finding a hierarchy for knowledge
obtained from source code. Other scenarios, as already stated in the opener of
this section, are based on product descriptions or sets of valid configurations
\citep{aleti_software_2013,bakar_feature_2015}. In the remainder of this
subsection, we will focus on organizing features and constraints extracted from
source code. For further reading, \cite{andersen_efficient_2012} present algorithms for structuring feature diagrams for three different scenarios including the ones previously mentioned.

Given an extracted set of features along with corresponding descriptions and
recovered constraints among the features, \cite{she_reverse_2011} propose a
semi-automated and interactive approach to synthesize a feature hierarchy.
Their approach comprises three tasks. First, an overall feature hierarchy based
on feature implications is specified. Second, potential feature groups are
detected and manually selected. Finally, the feature diagram is extended with
remaining CTCs. 
The approach by \cite{she_reverse_2011} provides a practical algorithm to synthesize a
feature diagram, yet has some limitations we need to consider. First, the
approach is not able to detect or-groups as defined in Sec. \ref{sec:variability_modeling}.
Second, the approach does introduce a root feature. Finally, the approach does not
distinguish between mandatory and optional features. Implicitly, all features
that do not have a parent feature are optional and all features that have a
parent feature are by default mandatory. \cite{she_reverse_2011} evaluated the
algorithm with both complete and incomplete variability knowledge (feature
names, descriptions and constraints). While the algorithm has shown to be
practical, detecting features whose parent was the root-feature was difficult
since, due to the transitive property of implication, it is implied by each
feature of the feature model.

%\begin{enumerate}
%  \item The algorithm commences with finding a single parent for each
%  feature and, thus, specifying a tree-like feature hierarchy. Based on the
%  given constraints, a directed acyclic graph (DAG) representing implication
%  relationships among features, a so-called \emph{implication graph}, is
%  constructed.
%  Every vertex in the implication graph represents a feature  and edges are
%  inserted for each pair of features $(u, v)$, where  $u \implies v$ holds with
%  % respect to the given constraints.
%   
%  In addition to the implication graph, the algorithm for each feature computes
%  two rankings of features that are likely to be the respective parent feature.
%  The two rankings both employ the feature descriptions. Feature descriptions
%  are compared for similarity using a similarity metric. For two features $p$
%  and $s$, the similarity is defined as the weighted sum of the inverse
%  % document frequencies $idf(w)$ for the words that both descriptions of
% features $p$%  and $s$ share.

%  The $idf$-ranking for a word $w$ is the logarithm of the number of features
%  divided by the number of features whose description contains $w$. Each $idf$
%  value is weighted with the frequency of $w$ in the description of
%  feature $p$.
  
%  The first ranking, called Ranked-Implied-Features (RIF), for each feature $f$
%  ranks all features by their similarity to $f$ in an descending order, but
%  prioritizes those features that are implied according to the previously
%  computed implication graph. The second ranking, called Ranked-All-Features
%  (RAF) is similar to RIF, yet less strict since implied features are not
%  prioritized. Given these rankings, a user for each feature selects a suitable
%  parent feature from the RIF or RAF ranking. The idea behind providing two
%  separate rankings, according to \cite{she_reverse_2011} is that the given
%  extracted constraints can be incomplete and, thus, not all relevant
%  implications are contained in the implication graph.

%  \item After the feature hierarchy is specified, another auxiliary graph, a
%  mutex graph, similar to the implication graph, is constructed. The
%  % \emph{mutex graph} is an undirected graph with features as vertices and
%  % edges between two
%  features $u$ and $v$, if $u \implies \neg{v}$ and $v \implies \neg{u}$ hold
%  with respect to the given constraints. 
%  That is, all adjacent features are mutually exclusive. Based on
%  this mutex graph, all maximal cliques (subsets of vertices that all are
%  connected with each other) among the vertices with the same parent are
%  computed. All features within such a clique are mutually exclusive and share
%  the same parent and represent mutex- or alternative-groups.
  % \cite{she_reverse_2011} introduce an additional constraint to extract xor-groups that require one of the groupsâ€™
%  features to be selected if the parent is selected. This distinction is in
%  line with the initial description of feature diagrams by
  % \cite{kang_feature-oriented_1990}, but not all descriptions of feature diagrams follow this distinction between
%  mutex- and xor-groups and just use the term alternative-group discussed in 
%  Sec. \ref{sec:variability_modeling}. %2.1
  
 % \item CTCs for the feature diagram are extracted from
 % the given configuration constraints. Since CTCs are constraints that could
 % not be represented by the feature hierarchy (implication) or
 % alternative-groups (exclusion), the derivation of CTCs follows this idea. The
%  set of cross-tree implications is derived by removing all edges that are part
%  of the feature hierarchy from the initially constructed implication graph.
%  The set of cross-tree exclusions is derived similarly from the mutex
%  graph by removing all edges among vertices of all mutex-groups. To make the
%  feature model sound, the given configuration constraints, reduced to those
%  clauses that are not already entailed by the diagram, can be added as an
%  additional CTC formula to the feature diagram \citep{she_reverse_2011}.
%\end{enumerate}

\subsection{Methodological Strategies}
The last two subsections reviewed a number of family-based analyses for
configurable software systems as well as approaches proposed to partially
extract variability models from a systemâ€™s code base. The latter approaches
presented, however, are rather isolated solutions due to non-generic
assumptions, such as the use of configuration APIs \citep{rabkin_static_2011},
or build-time variability \citep{nadi_where_2015}. At best, these approaches
complement each other, or are an appropriate choice under certain
circumstances, still requiring further manual assessment. The following
integrates the previously discussed work and proposes methodological strategies
to synthesize variability models for different scenarios, or use cases.

For the recovery of variability models, we propose three scenarios. Clearly,
this is not an exhaustive list, but covers the majority of use cases based on
our literature review. The scenarios should provide a practical context to the
previously mentioned techniques. The three scenarios are outlined in Table
\ref{tab:synthesis}; we derive our scenarios based on three criteria.
\emph{First}, we ask whether, and if so, to what extent configurability for a
software system is documented. \emph{Second}, we ask whether the software
system provides sample configurations, such as configuration presets, or
whether it ships as different variants, such as different Windows flavors.
\emph{Last}, we ask whether a variability model is explicitly contained in the
software, and whether it is visible to practitioners, such as the Kconfig
system for the Linux kernel. For each scenario, in Table \ref{tab:synthesis},
satisfaction of either criterion is marked. In addition, we mark criteria as
\emph{satisfied optionally}, if we assume them to be satisfied, but they are
not necessarily relevant for the choice of strategy.

\begin{table} 
	\centering
	\begin{tabular}{lccc}%
	\toprule
	\textbf{Criterion} & \textbf{Scenario A} & \textbf{Scenario B} &
	\textbf{Scenario C}
	\\
	\midrule
	\mbox{Configurability documentated?} & $\surd$ & $(\surd)$ & $(\surd)$ \\
	\mbox{Configurations provided?} & $\times$ & $\surd$ & $(\surd)$ \\
	\mbox{Variability model provided?} & $\times$ & $\times$ & $\surd$ \\
	\bottomrule
	\end{tabular}\\
	\vspace{1mm}
	{\footnotesize $\surd = \text{Criterion satisfied}$, $(\surd) =
	\text{Criterion satisfied optionally}$, $\times = \text{Criterion not
	satisfied}$}
	\caption{Distinction of three scenarios for variability model synthesis. }
	\label{tab:synthesis}
\end{table}

Apparently, the latter scenario C in Table \ref{tab:synthesis} requires only
little to no assessment of the application's variability, as the variability
model is already available.
For scenario A, both natural language artifacts and code artifacts must be
exploited. A basic start is to study and aggregate documentation information
about the software system with respect to configurations, such as manuals/man
pages or API documentation. While there is no template strategy to analyze
documentation artifacts manually, the key questions to be answered, along with
suitable methods to use are described in Table \ref{tab:manual_var_assessment}.

\begin{sidewaystable}
  \thisfloatpagestyle{empty}  
  \centering
  
  \begin{tabular}{L{0.25\textwidth} L{0.45\textwidth} L{0.3\textwidth}}
  
  	\toprule 
    {\bf Question} & {\bf What approach or technique to use?} & {\bf
    Information Gain} \\
    \midrule
    {How is variability implemented?\linebreak
	{\footnotesize\it Variability can be accommodated at build- or
	load-time, and can be implemented in various ways (cf. Section 3.1.1).}} & 
	
	{\small\begin{compactitem}
	  \item Review of the documentation with respect to configurability.
	  \item Family-based variability analyses help understand what parts of the
	  software are variable and how they are enabled, or made accessible.	  
	\end{compactitem}} & 
	
	{Knowledge of whether the software must be compiled for each configuration, or only for each version.}\\
	
	\midrule
	
	{How can the software be configured?\linebreak
	{\footnotesize\it Software can be configured at build-time or load-time
	(\ldots).}} &
	
	{\small\begin{compactitem}
	  \item Review of documentation with respect to installation of the software.
	\end{compactitem}} & 
	
	{Knowledge about how a configuration can be translated to a machine-readable
	format required by the software, such as argument lists or preprocessor annotations.}\\
	
	\midrule
	
	{Which configuration options exist, including types and domains?\linebreak
	{\footnotesize\it Configuration options can be binary or numeric options with
	respective domains.}} & 
	
	{\small\begin{compactitem}
	  \item Review of the documentation with respect to configurability.
	  \item NLP-based feature extraction using product or variant descriptons
	  \citep{alves_exploratory_2008,bakar_feature_2015}.
	  \item Feature Extraction via configuration API exploitation
	  \citep{rabkin_static_2011} .
	\end{compactitem}} & 
	
	{Knowledge about what configuration options exist, whether they are binary or
	numeric options, and what valid values can be assigned to them.}\\
	
	\midrule
	
	{Which dependencies or exist between and among configuration options?} & 
	
	{\small\begin{compactitem}
	  \item Constraint extraction from preprocessor annotations
	  \citep{nadi_mining_2014,nadi_where_2015}.
	  \item Approximation of feature constraints
	  \citep{lopez-herrejon_reverse_2012,linsbauer_feature_2014}.
	\end{compactitem}} & 
	
	{Obtaining a (approximated) variability model, which is required to decide
	whether a configuration is valid or not.}\\
	
	\midrule
	
	{Has the feature model been changed during evolution?} & 
	
	{\small\begin{compactitem} 
		\item Review of release notes and changes in the documentation with respect to
		new features as well as constraints added, modified, or removed. 
	\end{compactitem}} & 
	
	{Knowledge about whether synthesizing different versions of the variability
	model is required.}\\
    \bottomrule
  \end{tabular}
  \caption{Questionaire for manual variability
  assessment.}\label{tab:manual_var_assessment}
\end{sidewaystable}

For scenario B, despite documentation might be available, the
previously presented variability model approximation approaches
\citep{haslinger_reverse_2011,haslinger_extracting_2013,lopez-herrejon_reverse_2012,linsbauer_feature_2014}
can be applied, yet only binary configuration options are supported so far.
Given the existence of sample configuration or configuration presets, these
may provide additional information to answer the questions stated above. 
The remaining approaches mentioned in the previous subsections, unfortunately,
describe only isolated solutions. Given suitable circumstances, they can
nevertheless aid the extraction of variability models. The overall scheme in
synthesizing a variability model is to answer the the questions above manually,
and refer to automated tool support whenever possible.



\section{Configuration Generation}\label{sec:configuration_gen}
Apart from having knowledge about the variability of a configurable software
system, either in the form of a set of constraints among features, or a feature
diagram, we also need to derive all configurations, but at least meaningful
sample sets thereof, from the variability model. Variability models can be
expressed in various forms, such as propositional formulas or context-free
grammars (CFG) \citep{batory_feature_2005}, as well as constraint satisfaction
problems (CSP) \citep{benavides_automated_2005,benavides_using_2005}.
Accordingly, the all configurations represent solutions to propositional formulas or CSPs, and valid words for CFGs
respectively. That is, the generation of all configurations with respect to the
variability model is equivalent to finding a solution or word set for the
aforementioned representations of a variability model. In the following, we
look into how variability models can be encoded as a CSP and describe in detail
the configuration generation using CFGs.

\subsection{Constraint Satisfaction Problem}
A constraint satisfaction problem (CSP) in the context of variability modeling
describes a set of options ranging over finite domain as well as a set of
constraints which restrict which values variables can take simultaneously
\citep{benavides_automated_2005}. For a binary option $b$, the respective domain
$dom(b)$ simply is $\lbrace 0, 1\rbrace$.
For a numeric option, the respective domain $dom(n)$ is a finite set of legal
values with a minimum and a maximum value, say $\lbrace v_{min}, v_1,
v_2, \ldots, v_{max}\rbrace$.
A solution $s: O \rightarrow dom(o_1) \times dom(o_2) \times \ldots \times
dom(o_{|O|})$ to a CSP is an assignment of options $o_i \in O, i \in \mathbb{N}$
to values of their respective domain, such that all constraints are satisfied simultaneously \citep{benavides_automated_2005}.  

A solution to a CSP is found by systematically checking for different
selections of values whether all constraints are satisfied. There exists a
large number of ready-to-use SAT and CSP solvers, yet we are not covering CSP
solution here since it is beyond the scope of your thesis. For further reading, 
\citep{benavides_fama:_2007} present a tool with extensive analysis support for
various different presentations of variability models.

To encode a variability model as a CSP, \cite{benavides_automated_2005} describe
the following transformation rules:

\begin{itemize}
  \item For a parent feature $f$ and a child feature $fâ€™$, a mandatory
  relationship is expressed as $f \Leftrightarrow fâ€™$, and an optional relationship is
  expressed as $fâ€™ \implies f$.
    \item  For a parent feature $f$ and child features $f_i$, where $i = 1, 2,
    \ldots n$, an or-group is expressed as $f \Leftrightarrow f_1 \lor f_2 \lor
    \ldots \lor f_n$, and an alternative-group is expressed as $$\bigwedge_{i
    = 0}^n f_i \Leftrightarrow (f \land \bigwedge_{j \in \lbrack 0, n \rbrack
    \setminus i} \neg f_j) $$.
\end{itemize}

To also consider numeric options, the domain of a numeric option $n$ can be
conceived as an alternative-group since only one value from the domain can be
selected at a time. Hence, each value of the domain $dom(n)$ can be conceived as
a binary option. If value $v \in dom(n)$ is selected, this states $n = v$,
otherwise $n \neq v$.


\subsection{Grammar Expansion}
Besides trying to find solution for satisfiability problems, the expression of
variability models as context-free grammars (CFGs) enables the derivation of
configurations directly from a CFG by expanding it. A
first description of transformation rules, yet only for feature diagrams with
binary options, was was proposed by \cite{batory_feature_2005}. A hierarchical feature diagram
can be recovered from a set of constraints using the algorithm of
\cite{she_reverse_2011} as explained in section \ref{sec:feature_hierarchy}.
In the following we describe
how a feature diagram with both binary and numeric features can be transformed
to a context-free grammar, and how configurations can be derived subsequently.

\begin{definition}[Context-free Grammar]\label{def:cfg}
A context-free grammar is a tuple $G = (N, T, S, P)$, consisting of a set of
non-terminal symbols $N$, a set of terminal symbols $T$, a start word $S \in (N
\cup T)^*$, and a set of productions $P \subseteq N \times (N \cup T)^*$. The
set $L_G$ describes the language of the grammar $G$ and comprises all valid
words $w \in L_G$ which can be derived from the start word $S \in L_G$ by
applying productions a finite number of times to it.
\end{definition}

Following the Definition.~\ref{def:cfg}, to derive all configurations for a
given feature diagram, the idea is to first translate it to a context-free
grammar. In order to do so, especially with respect to handling numeric
options, we introduce an extended definition for a CFG, a configuration
generation grammar.

\begin{definition}[Configuration Generation Grammar]\label{def:cgg}
A configuration generation grammar is a context-free grammar $G = (N, T, S,
P)$ whose elements are constructed from a feature diagram as follows.

\begin{itemize}
  \item All features represent non-terminal symbols $N$, which can be divided
  into two disjoint sets, binary non-terminal symbols $F_\mathcal{B}$ and
  numeric non-terminal symbols $F_\mathcal{N}$. That is, $N = F_\mathcal{B}
  \cup F_\mathcal{N}$ and $F_\mathcal{B} \cap F_\mathcal{N} = \varnothing$.

  \item Similarly, the set of terminal symbols $T$ is consists of two different
  sets, the binary terminal symbols $T_\mathcal{B}$ and the numeric terminal
  symbols $T_\mathcal{N}$, so that $T = T_\mathcal{B} \cup T_\mathcal{N}$ and
  $T_\mathcal{B} \cap T_\mathcal{N} = \varnothing$ with
  
  \begin{equation}
  T_\mathcal{B} = \bigcup_{b\in F_\mathcal{B}} \lbrace b_0,  b_1\rbrace
  \end{equation}
  
  \begin{equation}
  T_\mathcal{N} = \bigcup_{n\in F_\mathcal{N}} ~ \bigcup_{v_i \in dom(n)}
  \lbrace n_{v_i}\rbrace.
  \end{equation}
  
  \item All productions $P$ are constructed from the hierarchy specified in the
  given feature diagram, the binary, and the numeric features. In our definition
  of a configuration grammar, each word $w$ is expressed as a subset of
  (non-)terminal symbols, i.e., $w \subseteq (N \cup T)$. A word is a terminal
  word, if and only if it does not contain any non-terminal symbol. Accordingly,
  the set of productions is $P \subseteq N \times (N \cup T)$, and a production
  $p = (u, v) \in P$ is applied to a word $w$ by removing non-terminal symbol
  $u$ from word $w$ and merging words $v$ and $w$. Hence, the new word $w'$ is
  defined as $w' = (w \setminus u) \cup v$.

  The productions $P = P_H \cup P_F$ are constructed from the following disjoint
  two sets of productions:
  
  \begin{equation}
  P_H = \lbrace (p, \lbrace c, c_1 \rbrace) | p, c \in N \land
  c \implies p\rbrace
  \end{equation}
  
  \begin{equation}
  P_F = \bigcup_{f \in (F_\mathcal{B} \cup F_\mathcal{N})} ~ \bigcup_{v \in
  dom(f)} \lbrace (f, v) \rbrace
  \end{equation}
	
  \item Finally, the start word $S \subseteq (N \cup T)$ consists the
  non-terminal representing the top-level feature in the given feature diagram.
  The set of respective configurations is described by all words which can be
  generated by a finite number of applications of productions to the start word
  $S$.
  
  \end{itemize}
\end{definition}

Based on definition \ref{def:cgg}, we can specify an algorithm that computes the
transitive closure of the grammar by repeatedly expanding each non-terminal for
each (partial) word until word containing non-terminal symbols is left.
In addition to deriving all configurations from a grammar, the
algorithm can also be used to derive partial configurations, such as
binary-only configurations. To do so, the numeric features need to be removed
from the set of non-terminal symbols. The only limitation of this algorithm is
that, conceptually, it requires all numeric options to be mandatory features.
This is due to the unspecified semantics of a numeric option being un- or
deselected.

%\begin{algorithm}[H]\label{alg:expand}
% \KwData{Configuration generation grammar $G = \lbrace N, T, S, P \rbrace$, and
% cross-tree constraints $C$ of the given variability model}
% \KwResult{All configurations of the given variability model.}
% \vspace{5mm}
% words = Queue()\;
% words.enqueue($S$)\;
% \While{words is not empty}{
%  current = words.dequeue()\;
%  \If{current does violate any cross-tree constraint}{
%   continue\;
%   }
%   \For{$n \in N$}{
%   		\If{$n \in current$}{
%   			\For{$u \in \lbrace u | (n, u) \in P \rbrace$}{
%   				new = current\;
%   				new = new $\setminus~ n$\;
%   				new = new $\cup~ u$\;
%   				\eIf{$N \cup new = \varnothing$}{
%   					yield new\;
%   				}{
%   					words.enqueue(new)\;
%   				}
%   			}
%   			break\;
%   		}
%   }
% }
 
% \caption{Expansion algorithm for a configuration generation grammar.}
%\end{algorithm}\vspace{2mm}

\section{Configuration Sampling}\label{sec:configuration_sam}
When assessing properties for configurable software systems, it is infeasible
to consider every possible variant. As previously stated in Section 2.x, with
variability, interactions between features can emerge and can be the root cause
for configuration-related faults. Hence, faults may only be uncovered under
specific configurations. To not exhaustively assess all variants, a variety of
strategies to select a sample set of configurations have been proposed.
Every sampling strategy in the context of configurable software system is
designed with respect to a \emph{coverage criterion} 
\citep{apel_feature-oriented_2013}. For instance, most feature interactions
happen to be pair-wise interactions, i.e., interactions between two features.
Based on this finding, t-wise sampling is one widely used
strategy, where configurations are part of the sample set, so that all t-tuples
of features are selected together. Thus, all t-wise feature interactions are
covered. 

\paragraph{Binary Features.}
Most sampling strategies in the context of configurable software systems
target binary features. Popular sampling strategies for sampling configurations
of binary features include, but are not limited to the following
\citep{apel_feature-oriented_2013,medeiros_comparison_2016} strategies listed in
Table \ref{tab:sampling}.

\begin{table}[h!]
	\centering
	\begin{tabular}{lp{11cm}}
	\toprule
	\textbf{Name} & \textbf{Description} \\
	\midrule
	Feature Coverage & Configurations are selected, so that each
  feature is selected in at least one configuration
  \citep{apel_feature-oriented_2013}.\\
  \midrule
  Most-enabled-disabled & Configurations are selected, so that a
  maximal and minimal number of features is enabled
  \citep{medeiros_comparison_2016}. \\
  \midrule
  One-enabled & Configurations are selected, so
  that each feature is enabled at a time \citep{abal_42_2014}. Similarly, with a
  \emph{one-disabled} strategy, configurations are chosen, so that each feature
  is deselected at a time. \\
  \midrule
  Statement-coverage & Configurations are
  selected, so that each variable block of code (for
  compile-time variability) is at least enabled in one
  variant \citep{tartler_static_2014}. \\
  \midrule
  T-wise sampling & Configurations are selected, so that all
  t-tuples of all (binary) features are included in at least one configuration
  \citep{williams_practical_1996}. That is, the upper bound for the sample size
  is $\binom{|F|}{t}$ for features $F$ and $t \in \mathbb{N}$.\\  
	\bottomrule
	\end{tabular}
	\caption{Selection of sampling strategies for binary features.}
	\label{tab:sampling}
\end{table}

\cite{medeiros_comparison_2016} have compared different sampling strategies,
among other things with respect to resulting sample size and fault detection
rate. \emph{Most-enabled-disabled} results in the smallest
sample size, whereas \emph{t-wise} sampling, especially for a greater $t$ yields
the largest samples. Regarding the detection of faults,
\emph{statement-coverage} performed poorly, whereas \emph{t-wise} sampled
samples, especially with a greater $t$ unveiled most faults. 

\paragraph{Numeric Features.}
Similar to selecting meaningful sample sets of binary options, for numeric
options, sampling strategies are designed with respect to covering possible
interactions. Subsumed under the term \emph{design of experiments} various
sampling strategies, or experimental plans have been proposed, each assigning values
(from an optionâ€™s domain) to independent variables (numeric options, in this
case) \citep{antony_design_2014}. As the choice of an experimental plan (for
both binary and numeric options) determines the number of measurements, and therefore the cost of
assessment, not all designs might scale and be suitable for our assessments.
\cite{siegmund_performance-influence_2015} have reviewed and evaluated a number
of established experimental plans with respect to feasibility. The authors exclude a number of
designs due to an infeasible number of measurements, and advocate the use of
four designs, including the Plackett-Burman Design and Random Designs. Assuming
a discrete domain of values for each numeric option, the former design requires
each combination of levels for each pair of numeric options to occur equally.
The latter design is advocated not least because of an negligible number of
constraints among numeric options \citep{siegmund_performance-influence_2015}.
For further reading on more detailed descriptions of experimental designs, refer
to \cite{antony_design_2014}. 

Depending on whether binary, numeric, or both
types of configurations options are present, sampling strategies are selected,
respectively. To derive mixed configurations, first, samples are selected from
both binary and numeric configuration options. Second, the final sample
of mixed configurations is computed as the cross-product of binary and numeric
partial configurations.
